{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering over Resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "import getpass \n",
    "from bardapi import Bard\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI & Bard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bard_token = getpass.getpass(\"Enter the token for Google Bard: \")\n",
    "bard = Bard(token=bard_token)\n",
    "\n",
    "openai_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TXT Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Test-Documents/state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "pages = text_splitter.split_text(state_of_the_union)\n",
    "db = Chroma.from_texts(pages, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(pages))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Test-Documents/wsj.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "db = Chroma.from_documents(pages, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='Test-Documents/Passwords.csv')\n",
    "data = loader.load()\n",
    "db = Chroma.from_documents(data, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "loader = UnstructuredHTMLLoader(\"nature.html\")\n",
    "data = loader.load()\n",
    "db = Chroma.from_documents(data, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
    "\n",
    "loader = UnstructuredMarkdownLoader(\"INPUT FILE PATH\")\n",
    "data = loader.load()\n",
    "db = Chroma.from_documents(data, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did president say about China?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "para = \"\"\n",
    "for each in docs: \n",
    "    para += each.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "chain = load_qa_with_sources_chain(model, chain_type=\"map_reduce\")\n",
    "openai_res = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "prompt = f\"I want you to work as a question answering machine over given documents. The documents you will be given is the following paragraph: {para}. Then, I want to you answer the question based on the given paragraph. The question is {query}\"\n",
    "bard_res = bard.get_answer(prompt)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president mentioned that we need to level the playing field with China and other competitors in order to compete for the best jobs of the future.\n",
      "SOURCES: 12\n",
      "\n",
      "In the given paragraph, President Biden said that he told Xi Jinping that it is never a good bet to bet against the American people. He also said that the United States needs to level the playing field with China and other competitors in order to compete for the best jobs of the future. He specifically mentioned the Bipartisan Innovation Act, which would make record investments in emerging technologies and American manufacturing.\n",
      "\n",
      "Here are some specific quotes from the paragraph that refer to China:\n",
      "\n",
      "* \"As I’ve told Xi Jinping, it is never a good bet to bet against the American people.\"\n",
      "* \"But to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\"\n",
      "* \"That’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing.\"\n",
      "\n",
      "Overall, President Biden's message is that the United States is committed to competing with China in the 21st century, but that it needs to do so on a level playing field. He believes that the Bipartisan Innovation Act is a key step in leveling the playing field and ensuring that the United States remains competitive in the years to come.\n"
     ]
    }
   ],
   "source": [
    "print(openai_res['output_text'] + \"\\n\")\n",
    "print(bard_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Translation Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Spanish\"\n",
    "translated = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"You are a {language} translator.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in {language}. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level f{language} words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. The paragrah you will translate is {bard_res}.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(translated[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight Original Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
