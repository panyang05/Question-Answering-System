{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering over Resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.cohere import CohereEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "import getpass \n",
    "from bardapi import Bard\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize OpenAI & Bard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bard_token = getpass.getpass(\"Enter the token for Google Bard: \")\n",
    "bard = Bard(token=bard_token)\n",
    "\n",
    "openai_key = getpass.getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ['OPENAI_API_KEY'] = openai_key\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TXT Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Test-Documents/state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "pages = text_splitter.split_text(state_of_the_union)\n",
    "db = Chroma.from_texts(pages, embeddings, metadatas=[{\"source\": str(i)} for i in range(len(pages))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"Test-Documents/wsj.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "db = Chroma.from_documents(pages, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='Test-Documents/Passwords.csv')\n",
    "data = loader.load()\n",
    "db = Chroma.from_documents(data, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'xpath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument_loaders\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnstructuredHTMLLoader\n\u001b[1;32m      3\u001b[0m loader \u001b[38;5;241m=\u001b[39m UnstructuredHTMLLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest-Documents/test.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/document_loaders/unstructured.py:71\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Document]:\n\u001b[1;32m     70\u001b[0m     \u001b[39m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     elements \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_elements()\n\u001b[1;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39melements\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     73\u001b[0m         docs: List[Document] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain/document_loaders/html.py:13\u001b[0m, in \u001b[0;36mUnstructuredHTMLLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_elements\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List:\n\u001b[1;32m     11\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39munstructured\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpartition\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhtml\u001b[39;00m \u001b[39mimport\u001b[39;00m partition_html\n\u001b[0;32m---> 13\u001b[0m     \u001b[39mreturn\u001b[39;00m partition_html(filename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49munstructured_kwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/unstructured/documents/elements.py:214\u001b[0m, in \u001b[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 214\u001b[0m     elements \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m     sig \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(func)\n\u001b[1;32m    216\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/unstructured/file_utils/filetype.py:531\u001b[0m, in \u001b[0;36madd_metadata_with_filetype.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    530\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 531\u001b[0m     elements \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    532\u001b[0m     sig \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(func)\n\u001b[1;32m    533\u001b[0m     params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mdict\u001b[39m(\u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/unstructured/partition/html.py:70\u001b[0m, in \u001b[0;36mpartition_html\u001b[0;34m(filename, file, text, url, encoding, include_page_breaks, include_metadata, headers, ssl_verify, parser, html_assemble_articles, metadata_filename, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m exactly_one(filename\u001b[39m=\u001b[39mfilename, file\u001b[39m=\u001b[39mfile, text\u001b[39m=\u001b[39mtext, url\u001b[39m=\u001b[39murl)\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m filename \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 70\u001b[0m     document \u001b[39m=\u001b[39m HTMLDocument\u001b[39m.\u001b[39;49mfrom_file(\n\u001b[1;32m     71\u001b[0m         filename,\n\u001b[1;32m     72\u001b[0m         parser\u001b[39m=\u001b[39;49mparser,\n\u001b[1;32m     73\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m     74\u001b[0m         assemble_articles\u001b[39m=\u001b[39;49mhtml_assemble_articles,\n\u001b[1;32m     75\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melif\u001b[39;00m file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     _, file_text \u001b[39m=\u001b[39m read_txt_file(file\u001b[39m=\u001b[39mfile, encoding\u001b[39m=\u001b[39mencoding)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/unstructured/documents/xml.py:134\u001b[0m, in \u001b[0;36mXMLDocument.from_file\u001b[0;34m(cls, filename, parser, stylesheet, encoding, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_file\u001b[39m(\n\u001b[1;32m    126\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    132\u001b[0m ):\n\u001b[1;32m    133\u001b[0m     _, content \u001b[39m=\u001b[39m read_txt_file(filename\u001b[39m=\u001b[39mfilename, encoding\u001b[39m=\u001b[39mencoding)\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_string(content, parser\u001b[39m=\u001b[39;49mparser, stylesheet\u001b[39m=\u001b[39;49mstylesheet, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/unstructured/documents/xml.py:121\u001b[0m, in \u001b[0;36mXMLDocument.from_string\u001b[0;34m(cls, text, parser, stylesheet, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mReading document from string ...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    120\u001b[0m doc \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(parser\u001b[39m=\u001b[39mparser, stylesheet\u001b[39m=\u001b[39mstylesheet, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 121\u001b[0m doc\u001b[39m.\u001b[39;49m_read_xml(text)\n\u001b[1;32m    122\u001b[0m \u001b[39mreturn\u001b[39;00m doc\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/unstructured/documents/xml.py:84\u001b[0m, in \u001b[0;36mXMLDocument._read_xml\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m<pre>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m</pre>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m content:\n\u001b[1;32m     83\u001b[0m     tree \u001b[39m=\u001b[39m etree\u001b[39m.\u001b[39mHTML(content)\n\u001b[0;32m---> 84\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m tree\u001b[39m.\u001b[39;49mxpath(\u001b[39m\"\u001b[39m\u001b[39m//pre\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     85\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m element\u001b[39m.\u001b[39mtext:\n\u001b[1;32m     86\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'xpath'"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredHTMLLoader\n",
    "\n",
    "loader = UnstructuredHTMLLoader(\"Test-Documents/test.html\")\n",
    "data = loader.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What did president say about China?\"\n",
    "docs = db.similarity_search(query)\n",
    "\n",
    "para = \"\"\n",
    "for each in docs: \n",
    "    para += each.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "chain = load_qa_with_sources_chain(model, chain_type=\"map_reduce\")\n",
    "openai_res = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
    "\n",
    "prompt = f\"I want you to work as a question answering machine over given documents. The documents you will be given is the following paragraph: {para}. Then, I want to you answer the question based on the given paragraph. The question is {query}\"\n",
    "bard_res = bard.get_answer(prompt)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The president mentioned that we need to level the playing field with China and other competitors in order to compete for the best jobs of the future.\n",
      "SOURCES: 12\n",
      "\n",
      "In the given paragraph, President Biden said that he told Xi Jinping that it is never a good bet to bet against the American people. He also said that the United States needs to level the playing field with China and other competitors in order to compete for the best jobs of the future. He specifically mentioned the Bipartisan Innovation Act, which would make record investments in emerging technologies and American manufacturing.\n",
      "\n",
      "Here are some specific quotes from the paragraph that refer to China:\n",
      "\n",
      "* \"As I’ve told Xi Jinping, it is never a good bet to bet against the American people.\"\n",
      "* \"But to compete for the best jobs of the future, we also need to level the playing field with China and other competitors.\"\n",
      "* \"That’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing.\"\n",
      "\n",
      "Overall, President Biden's message is that the United States is committed to competing with China in the 21st century, but that it needs to do so on a level playing field. He believes that the Bipartisan Innovation Act is a key step in leveling the playing field and ensuring that the United States remains competitive in the years to come.\n"
     ]
    }
   ],
   "source": [
    "print(openai_res['output_text'] + \"\\n\")\n",
    "print(bard_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Translation Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Spanish\"\n",
    "translated = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"You are a {language} translator.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"I will speak to you in any language and you will detect the language, translate it and answer in the corrected and improved version of my text, in {language}. I want you to replace my simplified A0-level words and sentences with more beautiful and elegant, upper level f{language} words and sentences. Keep the meaning same, but make them more literary. I want you to only reply the correction, the improvements and nothing else, do not write explanations. The paragrah you will translate is {bard_res}.\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(translated[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight Original Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
